
The goals of this project are as follows:

- Understand the architecture of recurrent neural networks (RNNs) and how they operate on sequences by sharing weights over time
- Understand and implement both Vanilla RNNs and Long-Short Term Memory (LSTM) RNNs
- Understand how to sample from an RNN language model at test-time
- Understand how to combine convolutional neural nets and recurrent nets to implement an image captioning system
- Understand how a trained convolutional network can be used to compute gradients with respect to the input image
- Implement and different applications of image gradients, including saliency maps, fooling images, class visualizations
- Understand and implement style transfer


### Q1: Image Captioning with Vanilla RNNs
In the Jupyter notebook `RNN_Captioning.ipynb`, implemente an image captioning system on MS-COCO using vanilla recurrent networks.

### Q2: Image Captioning with LSTMs
In the IPython notebook `BatchNormalization.ipynb` you will implement batch
normalization, and use it to train deep fully-connected networks.

### Q3: Network Visualization: Saliency maps, Class Visualization, and Fooling Images 
The Jupyter notebooks `NetworkVisualization-TensorFlow.ipynb`/`NetworkVisualization-PyTorch.ipynb` will introduce the pretrained SqueezeNet model, compute gradients with respect to images, and use them to produce saliency maps and fooling images. Please complete only one of the notebooks (TensorFlow or PyTorch).

### Q4: Style Transfer
In the Jupyter notebooks `StyleTransfer-TensorFlow.ipynb`/`StyleTransfer-PyTorch.ipynb` you will learn how to create images with the content of one image but the style of another. Please complete only one of the notebooks (TensorFlow or PyTorch). 
